# ================================================
# üìò GU√çA DE ESTUDIO: REDES NEURONALES RECURRENTES (RNN)
# ================================================

# ‚úÖ 1. Importaci√≥n de librer√≠as necesarias
import numpy as np                                # Para operaciones num√©ricas
import tensorflow as tf                           # Framework principal para deep learning
from tensorflow.keras.models import Sequential    # Modelo secuencial
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense  # Capas necesarias
from tensorflow.keras.preprocessing.sequence import pad_sequences # Padding de secuencias
from tensorflow.keras.datasets import imdb        # Dataset IMDB para clasificaci√≥n de texto
import matplotlib.pyplot as plt                   # Para visualizar resultados

# ‚úÖ Verificamos la versi√≥n de TensorFlow
print("TensorFlow version:", tf.__version__)  # Debe ser 2.15.0 o compatible con Python 3.10/3.11

# ‚úÖ 2. Cargar y preparar el dataset IMDB
vocab_size = 10000       # Limitamos el vocabulario a las 10,000 palabras m√°s frecuentes
maxlen = 200             # Todas las secuencias tendr√°n una longitud de 200 palabras

# Cargar los datos ya tokenizados (como secuencias de enteros)
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)

# Rellenamos (pad) o truncamos las secuencias a una longitud fija
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

# Mostramos las dimensiones
print("Tama√±o de entrenamiento:", x_train.shape)
print("Tama√±o de prueba:", x_test.shape)

# ‚úÖ 3. Construcci√≥n del modelo RNN
model = Sequential()

# Capa de Embedding (convierte IDs de palabras en vectores densos)
model.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=maxlen))

# Capa RNN simple con 32 unidades
model.add(SimpleRNN(units=32, return_sequences=False))  # return_sequences=False: solo salida final

# Capa densa de salida con activaci√≥n sigmoide (clasificaci√≥n binaria)
model.add(Dense(1, activation='sigmoid'))

# ‚úÖ 4. Compilaci√≥n del modelo
model.compile(
    optimizer='adam',                    # Optimizador adaptativo
    loss='binary_crossentropy',         # P√©rdida para clasificaci√≥n binaria
    metrics=['accuracy']                # M√©trica de precisi√≥n
)

# Mostrar arquitectura
model.summary()

# ‚úÖ 5. Entrenamiento del modelo
history = model.fit(
    x_train, y_train,
    epochs=5,                   # 5 iteraciones completas sobre los datos
    batch_size=128,             # Tama√±o de lote
    validation_split=0.2        # 20% para validaci√≥n interna
)

# ‚úÖ 6. Visualizaci√≥n de resultados
plt.figure(figsize=(12, 5))

# Precisi√≥n
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Validaci√≥n')
plt.title('Precisi√≥n por √©poca')
plt.xlabel('√âpocas')
plt.ylabel('Precisi√≥n')
plt.grid(True)
plt.legend()

# P√©rdida
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validaci√≥n')
plt.title('P√©rdida por √©poca')
plt.xlabel('√âpocas')
plt.ylabel('P√©rdida')
plt.grid(True)
plt.legend()

plt.tight_layout()
plt.show()

# ‚úÖ 7. Evaluaci√≥n final del modelo
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"\nüìå Precisi√≥n en el conjunto de prueba: {test_accuracy * 100:.2f}%")
